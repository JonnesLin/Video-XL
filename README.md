
## Video-XL Family: Efficient VLMs for Extremely Long Video Understanding


## News
- [2025/03/16] ðŸŽ‰ [Video-XL-Pro](Video-XL-Pro) is released, which can process 10000 frames on an 80G GPU and achieves promising results with only 3B parameters.
- [2025/02/27] ðŸŽ‰ Video-XL has been accepted by CVPR 2025!
- [2024/12/22] ðŸ”¥ Most of the training data is released, including private baai-caption video data and VICO data. Feel free to use it in [link](https://huggingface.co/datasets/sy1998/Video_XL_Training/tree/main). 
- [2024/10/17] ðŸ”¥ Video-XL-7B weight is released, which can process max 1024 frames. 
- [2024/10/15] ðŸ”¥ [Video-XL](Video-XL) is released,  including model, training and evaluation code.



## Citation
If you find this repository useful, please consider giving a star :star: and citation

```
@article{shu2024video,
  title={Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding},
  author={Shu, Yan and Zhang, Peitian and Liu, Zheng and Qin, Minghao and Zhou, Junjie and Huang, Tiejun and Zhao, Bo},
  journal={arXiv preprint arXiv:2409.14485},
  year={2024}
}
```

## Acknowledgement
- LongVA: the codebase we built upon. 
- LMMs-Eval: the codebase we used for evaluation.
- Activation Beacon: The compression methods we referring.

## License
This project utilizes certain datasets and checkpoints that are subject to their respective original licenses. Users must comply with all terms and conditions of these original licenses.
The content of this project itself is licensed under the [Apache license 2.0](./LICENSE).




