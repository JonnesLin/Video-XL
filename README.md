<p align="center">
    <img src="https://github.com/VectorSpaceLab/Video-XL/blob/main/assets/logo.jpg" width="200" style="margin-bottom: 0.2;"/>
</p>

<h3 align="center" style="font-size: 50px;">
    <a style="color:#9C276A;">
        Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding
    </a>
</h3>
<h5 align="center"> If our project helps you, please give us a star ‚≠ê on GitHub to support us. üôèüôè </h5>

## Overview
Video-XL is an extra-long vision language model for hour-scale video understanding. With LLM compression, Video-XL can easily extend VLM to longer visual contexts wihout inforamtion loss. 

‚ú® Highlights:

(i) Comprehensive long video understanding. Video-XL 7B achieves the leading performance among 7B models on MLVU, VideoMME, VNBench and LongVideoBench.

(ii) Efficient Long visual context processing. Video-XL can process 1024 frames on an 80G GPU and achieves 100% accuracy on Needle-in-a-haystack evaluation.

(iii) Video-XL shows strong ability in some real-world scenarios, like video summarization, surveillance anomaly detection and Ad placement identification.


<p align="center">
  <img src="./assets/needle.png" alt="Results on Needle-in-a-haystack evaluation on a single 80G GPU." />
</p>

<p align="center"><em>Results on Needle-in-a-haystack evaluation on a single 80G GPU.</em></p>



## Plan

 - [ ] Technical Report
 - [ ] Model
 - [ ] Code
 - [ ] Data


